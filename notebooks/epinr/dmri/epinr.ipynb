{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cea842",
   "metadata": {},
   "source": [
    "# EPINR - Susceptibility Distortion Correction for Diffusion MRIs with Implicit Neural Representations\n",
    "\n",
    "Tyler Spears, Tom Fletcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_path():\n",
    "    # Adds the notebook's directory to sys.path for imports.\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    nb_path = None\n",
    "    # Try VSCode variable first.\n",
    "    ipy_session = get_ipython()\n",
    "    if ipy_session is not None:\n",
    "        nb_path = ipy_session.user_ns.get(\"__vsc_ipynb_file__\", None)\n",
    "        if nb_path is None:\n",
    "            nb_path = globals().get(\"__session__\", None)\n",
    "    if nb_path is None:\n",
    "        # Try Jupyter environment variable next.\n",
    "        nb_path = os.environ.get(\"JPY_SESSION_NAME\", None)\n",
    "    if nb_path is None:\n",
    "        # Fallback: use current working directory.\n",
    "        nb_path = Path(os.getcwd()).resolve()\n",
    "\n",
    "    return Path(nb_path).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# %autoreload 2\n",
    "# %matplotlib ipympl\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"0\")\n",
    "# By default, allow memory allocation to expand to avoid OOM errors\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = os.environ.get(\n",
    "    \"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\"\n",
    ")\n",
    "# Force torch.load to use 'weights_only=False' by default, unless specified.\n",
    "# <https://pytorch.org/docs/main/notes/serialization.html#environment-variables>\n",
    "os.environ[\"TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD\"] = os.environ.get(\n",
    "    \"TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD\", \"1\"\n",
    ")\n",
    "# <https://github.com/pytorch/pytorch/issues/121197> and\n",
    "# <https://github.com/NVIDIA/NeMo-Curator/pull/34>\n",
    "os.environ[\"TORCHINDUCTOR_COMPILE_THREADS\"] = os.environ.get(\n",
    "    \"TORCHINDUCTOR_COMPILE_THREADS\", \"2\"\n",
    ")\n",
    "ENABLE_CUDNN_BENCHMARK = bool(int(os.environ.get(\"ENABLE_CUDNN_BENCHMARK\", \"1\")))\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# from dataclasses import dataclass\n",
    "import collections\n",
    "import dataclasses\n",
    "import tempfile\n",
    "import copy\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, Literal, Callable\n",
    "\n",
    "import torch.multiprocessing as multiprocessing  # noqa\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from box import Box\n",
    "import yaml\n",
    "\n",
    "# visualization libraries\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import monai\n",
    "import monai.data\n",
    "import monai.transforms\n",
    "import monai.losses\n",
    "\n",
    "# Computation & ML libraries.\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.func\n",
    "\n",
    "# The flag below controls whether to allow TF32 on matmul. Defaults to False\n",
    "# in PyTorch 1.12 and later. See\n",
    "# <https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices>\n",
    "# for details.\n",
    "##\n",
    "# Set this to True to force full precision matmuls, as registration can be sensitive to\n",
    "# precision. Pytorch may complain, but the performance hit is (probably) worth the\n",
    "# gain in precision.\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.set_float32_matmul_precision(\"highest\")\n",
    "# The flag below controls whether to allow TF32 on cuDNN. Defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "##\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.set_float32_matmul_precision(\"medium\")\n",
    "# # The flag below controls whether to allow TF32 on cuDNN. Defaults to True.\n",
    "# torch.backends.cudnn.allow_tf32 = True\n",
    "# ##\n",
    "# # Activate cudnn benchmarking to optimize convolution algorithm speed.\n",
    "# if torch.backends.cudnn.enabled and ENABLE_CUDNN_BENCHMARK:\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import mrinr\n",
    "\n",
    "\n",
    "# Add the notebook's directory to sys.path for imports.\n",
    "nb_path = get_nb_path()\n",
    "if str(nb_path) not in sys.path:\n",
    "    sys.path.insert(0, str(nb_path))\n",
    "from data_utils import (\n",
    "    PE_DIR_ALIASES,\n",
    "    DWISubjectData,\n",
    "    scale_vol,\n",
    "    blur_mask,\n",
    "    load_dwi_subject_data,\n",
    "    central_diff_det_j,\n",
    ")\n",
    "from loss_utils import (\n",
    "    WeightedNMIParzenLoss,\n",
    "    NCC,\n",
    "    DoGLaplacian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f78ed",
   "metadata": {},
   "source": [
    "## Function & Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93613193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siren(torch.nn.Module):\n",
    "    \"\"\"SIREN implicit neural representation.\n",
    "\n",
    "    From:\n",
    "    V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein,\n",
    "        “Implicit Neural Representations with Periodic Activation Functions.”\n",
    "        arXiv, Jun. 17, 2020. doi: 10.48550/arXiv.2006.09661.\n",
    "\n",
    "    Implementation adapated from <https://github.com/lucidrains/siren-pytorch>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        num_layers,\n",
    "        omega=1.0,\n",
    "        omega_0=30.0,\n",
    "        c: float = 6.0,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_features = hidden_features\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.c = c\n",
    "\n",
    "        layers = list()\n",
    "        for idx in range(num_layers):\n",
    "            is_first = idx == 0\n",
    "            omega_i = omega_0 if is_first else omega\n",
    "            in_features_i = self.in_features if is_first else self.hidden_features\n",
    "\n",
    "            layer = SirenBlock(\n",
    "                omega=omega_i,\n",
    "                is_first_layer=is_first,\n",
    "                c=self.c,\n",
    "                use_activation=True,\n",
    "                in_features=in_features_i,\n",
    "                out_features=self.hidden_features,\n",
    "                bias=bias,\n",
    "            )\n",
    "\n",
    "            layers.append(layer)\n",
    "\n",
    "        # Final layer without activation or bias. As a displacement field, there should\n",
    "        # be no global translation component, so the bias is disabled.\n",
    "        final_layer = SirenBlock(\n",
    "            omega=omega,\n",
    "            c=self.c,\n",
    "            is_first_layer=False,\n",
    "            use_activation=False,\n",
    "            in_features=self.hidden_features,\n",
    "            out_features=self.out_features,\n",
    "            bias=False,\n",
    "        )\n",
    "        layers.append(final_layer)\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, return_intermediates: bool = False):\n",
    "        if not return_intermediates:\n",
    "            y = self.linear_layers(x)\n",
    "        else:\n",
    "            y_i = x\n",
    "            intermediates = list()\n",
    "            for lin in self.linear_layers:\n",
    "                y_i = lin(y_i)\n",
    "                intermediates.append(y_i)\n",
    "            y = intermediates[-1], tuple(intermediates[:-1])\n",
    "        return y\n",
    "\n",
    "\n",
    "class SirenBlock(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        omega: float,\n",
    "        is_first_layer: bool,\n",
    "        c: float = 6,\n",
    "        use_activation: bool = True,\n",
    "        activate_fn_kwargs: dict = dict(),\n",
    "        **linear_kwargs,\n",
    "    ):\n",
    "        \"\"\"SIREN implicit neural representation linear and activation block.\n",
    "\n",
    "        From:\n",
    "        V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein,\n",
    "            “Implicit Neural Representations with Periodic Activation Functions.”\n",
    "            arXiv, Jun. 17, 2020. doi: 10.48550/arXiv.2006.09661.\n",
    "\n",
    "        Implementation adapated from <https://github.com/lucidrains/siren-pytorch>\n",
    "        and <https://github.com/vsitzmann/siren/blob/master/explore_siren.ipynb>.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        omega : float\n",
    "            Sine scale parameter; determines sine weight and linear weight init.\n",
    "\n",
    "            In the original paper, omega = 30 was chosen for many tests.\n",
    "        is_first_layer : bool\n",
    "            Indicator for being the first layer in the INR MLP.\n",
    "        c : float, optional\n",
    "            Constant to drive initial weight distribution, by default 6.\n",
    "\n",
    "            This should probably not be changed, but it probably shouldn't be hardcoded.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(**linear_kwargs)\n",
    "        if use_activation:\n",
    "            self.activate_fn = mrinr.nn.Sine(omega, **activate_fn_kwargs)\n",
    "        else:\n",
    "            self.activate_fn = None\n",
    "\n",
    "        self._init_siren_linear_(\n",
    "            self.linear, omega=omega, is_first_layer=is_first_layer, c=c\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        if self.activate_fn is not None:\n",
    "            y = self.activate_fn(y)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_siren_linear_(\n",
    "        l: torch.nn.Linear,\n",
    "        omega: float,\n",
    "        is_first_layer: bool,\n",
    "        c: float,\n",
    "    ):\n",
    "        n = l.in_features\n",
    "        if is_first_layer:\n",
    "            omega_bound = 1 / n\n",
    "        else:\n",
    "            omega_bound = math.sqrt(c / n) / omega\n",
    "        torch.nn.init.uniform_(l.weight, -omega_bound, omega_bound)\n",
    "        if l.bias is not None:\n",
    "            torch.nn.init.uniform_(l.bias, -omega_bound, omega_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPINR SIREN model with optional positional encoding and rigid affine layer.\n",
    "\n",
    "\n",
    "class EPINR(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_features: int,\n",
    "        num_layers: int,\n",
    "        pe_dir: str,\n",
    "        omega=1.0,\n",
    "        omega_0=30.0,\n",
    "        c: float = 6.0,\n",
    "        non_rigid_affine: bool = False,\n",
    "        non_rigid_affine_nonzero_thresh: Optional[float] = None,\n",
    "        refine_fixed_rigid_affine: bool = False,\n",
    "        bias=True,\n",
    "        pos_enc: Optional[Literal[\"positional\"] | Literal[\"gaussian\"]] = None,\n",
    "        sigma: Optional[float] = None,\n",
    "        m_num_freqs: Optional[int] = None,\n",
    "    ):\n",
    "        self._init_kwargs = mrinr.nn.get_module_init_kwargs(\n",
    "            locals(), extra_kwargs_dict=dict()\n",
    "        )\n",
    "        super().__init__()\n",
    "        self.spatial_dims = 3\n",
    "        self.in_features = self.spatial_dims\n",
    "        self.pe_dir = pe_dir\n",
    "        if self.pe_dir not in {\"ap\", \"pa\"}:\n",
    "            raise NotImplementedError(f\"Unsupported pe_dir: {self.pe_dir}\")\n",
    "\n",
    "        if non_rigid_affine:\n",
    "            self.nonrigid_affine_layer = self._NonRigidAffineLayer(\n",
    "                pe_dir=self.pe_dir,\n",
    "                param_softshrink_lambda=non_rigid_affine_nonzero_thresh,\n",
    "            )\n",
    "        else:\n",
    "            self.nonrigid_affine_layer = None\n",
    "\n",
    "        self.out_features = 1\n",
    "        self.pos_enc_sigma = sigma\n",
    "        self.m_num_freqs = m_num_freqs\n",
    "        if pos_enc == \"positional\":\n",
    "            self.pos_enc = mrinr.nn.PositionalCoordEncoding(\n",
    "                spatial_dims=self.spatial_dims,\n",
    "                sigma_scale=self.pos_enc_sigma,\n",
    "                m_num_freqs=self.m_num_freqs,\n",
    "            )\n",
    "            siren_in_features = self.pos_enc.out_features\n",
    "        elif pos_enc == \"gaussian\":\n",
    "            self.pos_enc = mrinr.nn.GaussianCoordEncodingPreSampled(\n",
    "                spatial_dims=self.spatial_dims,\n",
    "                sigma=self.pos_enc_sigma,\n",
    "                m_num_freqs=self.m_num_freqs,\n",
    "            )\n",
    "            siren_in_features = self.pos_enc.out_features\n",
    "        else:\n",
    "            self.pos_enc = None\n",
    "            siren_in_features = self.spatial_dims\n",
    "\n",
    "        self.siren = Siren(\n",
    "            in_features=siren_in_features,\n",
    "            hidden_features=hidden_features,\n",
    "            out_features=self.out_features,\n",
    "            num_layers=num_layers,\n",
    "            omega=omega,\n",
    "            omega_0=omega_0,\n",
    "            c=c,\n",
    "            bias=bias,\n",
    "        )\n",
    "        #!TESTING\n",
    "        # Initialize the final layer weights to be very small to start as a small\n",
    "        # displacement field.\n",
    "        with torch.no_grad():\n",
    "            final_layer_init_range = 0.0001  # 0.000001\n",
    "            torch.nn.init.uniform_(\n",
    "                self.siren.linear_layers[-1].linear.weight,\n",
    "                -final_layer_init_range,\n",
    "                final_layer_init_range,\n",
    "            )\n",
    "        #!\n",
    "        if refine_fixed_rigid_affine:\n",
    "            self.fixed_rigid_affine = self._RigidAffineLayer()\n",
    "        else:\n",
    "            self.fixed_rigid_affine = None\n",
    "\n",
    "    class _RigidAffineLayer(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.spatial_dims = 3\n",
    "            self.theta = torch.nn.Parameter(torch.zeros(self.spatial_dims))\n",
    "            self.translations = torch.nn.Parameter(torch.zeros(self.spatial_dims))\n",
    "\n",
    "        def get_affine(self, homogeneous: bool = False):\n",
    "            R_x = torch.eye(self.spatial_dims).to(self.theta)\n",
    "            # [1, 0, 0],\n",
    "            # [0, torch.cos(self.theta[0]), -torch.sin(self.theta[0])],\n",
    "            # [0, torch.sin(self.theta[0]), torch.cos(self.theta[0])],\n",
    "            R_x[1, 1] *= torch.cos(self.theta[0])\n",
    "            R_x[1, 2] += -torch.sin(self.theta[0])\n",
    "            R_x[2, 1] += torch.sin(self.theta[0])\n",
    "            R_x[2, 2] *= torch.cos(self.theta[0])\n",
    "\n",
    "            R_y = torch.eye(self.spatial_dims).to(self.theta)\n",
    "            # [torch.cos(self.theta[1]), 0, torch.sin(self.theta[1])],\n",
    "            # [0, 1, 0],\n",
    "            # [-torch.sin(self.theta[1]), 0, torch.cos(self.theta[1])]\n",
    "            R_y[0, 0] *= torch.cos(self.theta[1])\n",
    "            R_y[0, 2] += torch.sin(self.theta[1])\n",
    "            R_y[2, 0] += -torch.sin(self.theta[1])\n",
    "            R_y[2, 2] *= torch.cos(self.theta[1])\n",
    "\n",
    "            R_z = torch.eye(self.spatial_dims).to(self.theta)\n",
    "            # [torch.cos(self.theta[2]), -torch.sin(self.theta[2]), 0],\n",
    "            # [torch.sin(self.theta[2]), torch.cos(self.theta[2]), 0],\n",
    "            # [0, 0, 1],\n",
    "            R_z[0, 0] *= torch.cos(self.theta[2])\n",
    "            R_z[0, 1] += -torch.sin(self.theta[2])\n",
    "            R_z[1, 0] += torch.sin(self.theta[2])\n",
    "            R_z[1, 1] *= torch.cos(self.theta[2])\n",
    "\n",
    "            R = R_x @ R_y @ R_z\n",
    "            if homogeneous:\n",
    "                A = torch.eye(\n",
    "                    self.spatial_dims + 1,\n",
    "                    device=self.translations.device,\n",
    "                    dtype=self.translations.dtype,\n",
    "                )\n",
    "                A[: self.spatial_dims, : self.spatial_dims] = R\n",
    "                A[:-1, -1] = self.translations\n",
    "                r = A\n",
    "            else:\n",
    "                r = R, self.translations\n",
    "            return r\n",
    "\n",
    "        def forward(self, x):\n",
    "            R, t = self.get_affine(homogeneous=False)\n",
    "            y = einops.einsum(x, R, \"... i, i j -> ... j\") + t\n",
    "            # linear() requires a transposed matrix.\n",
    "            # y = torch.nn.functional.linear(x, weight=R.T, bias=self.translations)\n",
    "            return y\n",
    "\n",
    "    class _NonRigidAffineLayer(torch.nn.Module):\n",
    "        def __init__(\n",
    "            self,\n",
    "            pe_dir: str,\n",
    "            param_softshrink_lambda: Optional[float] = None,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            self.spatial_dims = 3\n",
    "            self.pe_dir = pe_dir\n",
    "            if self.pe_dir not in {\"ap\", \"pa\"}:\n",
    "                raise NotImplementedError(f\"Unsupported pe_dir: {self.pe_dir}\")\n",
    "            self.scales = torch.nn.Parameter(torch.ones(self.spatial_dims))\n",
    "            self.shears = torch.nn.Parameter(torch.zeros(self.spatial_dims))\n",
    "            if (param_softshrink_lambda is None) or (param_softshrink_lambda == 0.0):\n",
    "                self.param_nonlinear = None\n",
    "            else:\n",
    "                self.param_nonlinear = torch.nn.Softshrink(\n",
    "                    lambd=param_softshrink_lambda\n",
    "                )\n",
    "\n",
    "        def get_affine(self, homogeneous: bool = False):\n",
    "            # Apply nonlinear to parameters so they remain at identity when only small\n",
    "            # updates are made, ensuring that large gradients are needed to \"activate\"\n",
    "            # the affine transformation.\n",
    "            if self.param_nonlinear is not None:\n",
    "                scales = self.param_nonlinear(self.scales - 1.0) + 1.0\n",
    "                shears = self.param_nonlinear(self.shears)\n",
    "            else:\n",
    "                scales = self.scales\n",
    "                shears = self.shears\n",
    "            # Scaling matrix.\n",
    "            S = torch.diag(scales)\n",
    "            # Shear matrix.\n",
    "            P = torch.eye(self.spatial_dims, dtype=shears.dtype, device=shears.device)\n",
    "            P[0, 1] = shears[0]  # shear xy\n",
    "            # shear xz, which is 0 for AP/PA PE directions.\n",
    "            P[0, 2] = shears[1] * 0.0\n",
    "            P[1, 2] = shears[2]  # shear yz\n",
    "\n",
    "            A = S @ P\n",
    "            if homogeneous:\n",
    "                A = torch.nn.functional.pad(A, pad=(0, 1, 0, 1), value=0.0)\n",
    "                A[-1, -1] = 1.0\n",
    "            return A\n",
    "\n",
    "    def get_extra_state(self) -> Any:\n",
    "        return {\"init_kwargs\": self._init_kwargs}\n",
    "\n",
    "    def set_extra_state(self, state):\n",
    "        return\n",
    "\n",
    "    def fixed2moving_rigid_affine_parameters(self):\n",
    "        if self.fixed_rigid_affine is not None:\n",
    "            return self.fixed_rigid_affine.parameters()\n",
    "        else:\n",
    "            return list()\n",
    "\n",
    "    def moving2fixed_nonrigid_affine_parameters(self):\n",
    "        if self.nonrigid_affine_layer is not None:\n",
    "            return self.nonrigid_affine_layer.parameters()\n",
    "        else:\n",
    "            return list()\n",
    "\n",
    "    def network_parameters(self):\n",
    "        p_iter_all = self.parameters()\n",
    "        fix2mov_rigid_params = list(self.fixed2moving_rigid_affine_parameters())\n",
    "        mov2fix_nonrigid_params = list(self.moving2fixed_nonrigid_affine_parameters())\n",
    "        affine_params = set(fix2mov_rigid_params + mov2fix_nonrigid_params)\n",
    "        net_params = [p for p in p_iter_all if p not in affine_params]\n",
    "        return net_params\n",
    "\n",
    "    @property\n",
    "    def fixed2moving_rigid_affine(\n",
    "        self,\n",
    "    ) -> mrinr.typing.SingleHomogeneousAffine3D | None:\n",
    "        if self.fixed_rigid_affine is not None:\n",
    "            A = self.fixed_rigid_affine.get_affine(homogeneous=True)\n",
    "        else:\n",
    "            A = None\n",
    "        return A\n",
    "\n",
    "    def apply_fixed_rigid_affine(\n",
    "        self, x: mrinr.typing.CoordGrid3D\n",
    "    ) -> mrinr.typing.CoordGrid3D:\n",
    "        if self.fixed_rigid_affine is not None:\n",
    "            y = self.fixed_rigid_affine(x)\n",
    "        else:\n",
    "            y = x\n",
    "        return y\n",
    "\n",
    "    def _get_reshape_fns(\n",
    "        self,\n",
    "        x: mrinr.typing.CoordGrid3D | torch.Tensor,\n",
    "        grid_fov: torch.Tensor,\n",
    "        grid_min_coord: torch.Tensor,\n",
    "    ) -> tuple[Callable, Callable]:\n",
    "        \"\"\"Get functions to reshape coordinates to/from grids.\n",
    "\n",
    "        Helps with handling inputs that are either full coordinate grids or just\n",
    "        batches of coordinates, the latter of which is useful for Jacobian/Hessian computations.\"\"\"\n",
    "        assert x.ndim == grid_fov.ndim == grid_min_coord.ndim, (\n",
    "            f\"Input shapes mismatch: {x.shape =}, {grid_fov.shape =}, {grid_min_coord.shape =}\"\n",
    "        )\n",
    "        x_orig_shape = tuple(x.shape)\n",
    "        if x.ndim <= 2 and x.shape[-1] == self.spatial_dims:\n",
    "            if x.ndim == 1:\n",
    "                coords_to_grid_reshape = lambda a: einops.repeat(\n",
    "                    a,\n",
    "                    \"coord -> b x y z coord\",\n",
    "                    b=1,\n",
    "                    x=1,\n",
    "                    y=1,\n",
    "                    z=1,\n",
    "                    coord=self.spatial_dims,\n",
    "                )\n",
    "                grid_to_coords_reshape = lambda a: einops.rearrange(\n",
    "                    a,\n",
    "                    \"b x y z coord -> (b x y z) coord\",\n",
    "                    b=1,\n",
    "                    x=1,\n",
    "                    y=1,\n",
    "                    z=1,\n",
    "                    coord=self.spatial_dims,\n",
    "                ).squeeze(0)\n",
    "            else:\n",
    "                coords_to_grid_reshape = lambda a: einops.rearrange(\n",
    "                    a,\n",
    "                    \"(b x y z) coord -> b x y z coord\",\n",
    "                    x=1,\n",
    "                    y=1,\n",
    "                    z=1,\n",
    "                    coord=self.spatial_dims,\n",
    "                )\n",
    "                grid_to_coords_reshape = lambda a: einops.rearrange(\n",
    "                    a,\n",
    "                    \"b x y z coord -> (b x y z) coord\",\n",
    "                    b=x_orig_shape[0],\n",
    "                    coord=self.spatial_dims,\n",
    "                )\n",
    "        else:\n",
    "            # Identity functions.\n",
    "            coords_to_grid_reshape = lambda a: a\n",
    "            grid_to_coords_reshape = lambda a: a\n",
    "        return coords_to_grid_reshape, grid_to_coords_reshape\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: mrinr.typing.CoordGrid3D | torch.Tensor,\n",
    "        grid_fov: torch.Tensor,\n",
    "        grid_min_coord: torch.Tensor,\n",
    "        _scale_by_fov: bool = True,\n",
    "        _add_nonrigid: bool = True,\n",
    "    ) -> mrinr.typing.CoordGrid3D:\n",
    "        # print(f\"{x.shape =}, {grid_fov.shape =}, {grid_min_coord.shape =}\")\n",
    "        # Inputs should be 3D coordinate grids, but if they are just a batch of 3D\n",
    "        # coordinates, then reshape to a grid.\n",
    "        coords_to_grid_reshape, grid_to_coords_reshape = self._get_reshape_fns(\n",
    "            x, grid_fov, grid_min_coord\n",
    "        )\n",
    "        x = coords_to_grid_reshape(x)\n",
    "        grid_fov = coords_to_grid_reshape(grid_fov)\n",
    "        grid_min_coord = coords_to_grid_reshape(grid_min_coord)\n",
    "\n",
    "        # Use a learned non-rigid affine transformation to create a secondary displacement\n",
    "        # field.\n",
    "        if self.nonrigid_affine_layer is not None:\n",
    "            # Broadcast batch dim.\n",
    "            A = self.nonrigid_affine_layer.get_affine(homogeneous=True).unsqueeze(0)\n",
    "            Ax = mrinr.coords.transform_coords(x, affine_a2b=A, broadcast_batch=True)\n",
    "            y_nonrigid = Ax - x\n",
    "        else:\n",
    "            y_nonrigid = None\n",
    "\n",
    "        # Scale the input coordinates to the range [-1, 1] based on the entire volume's\n",
    "        # field of view and lowest coordinate.\n",
    "        norm_x = (((x - grid_min_coord) / grid_fov) * 2.0) - 1.0\n",
    "\n",
    "        # Positional encoding of input coordinates.\n",
    "        if self.pos_enc is not None:\n",
    "            x_enc = self.pos_enc(norm_x)\n",
    "        else:\n",
    "            x_enc = mrinr.nn.coords_as_channels(norm_x, has_batch_dim=True)\n",
    "        x_enc = einops.rearrange(x_enc, \"b c x y z -> (b x y z) c\")\n",
    "        y = self.siren(x_enc)\n",
    "        # Reshape back into a coordinate grid, and return.\n",
    "        y = einops.rearrange(\n",
    "            y,\n",
    "            \"(b x y z) coord -> b x y z coord\",\n",
    "            x=x.shape[1],\n",
    "            y=x.shape[2],\n",
    "            z=x.shape[3],\n",
    "        )\n",
    "\n",
    "        y = torch.cat([torch.zeros_like(y), y, torch.zeros_like(y)], dim=-1)\n",
    "        # Unscale the output coordinates to the grid.\n",
    "        # y = (y * grid_fov) + grid_min_coord\n",
    "        if _scale_by_fov:\n",
    "            y = y * grid_fov\n",
    "        if y_nonrigid is not None and _add_nonrigid:\n",
    "            y = y + y_nonrigid\n",
    "        y = grid_to_coords_reshape(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1846db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization functions using pytorch's functional jacobian and hessian.\n",
    "def jacobian_matrix_batched(\n",
    "    pred_displacement_net: torch.nn.Module,\n",
    "    x_coords: mrinr.typing.ScalarVolume,\n",
    "    grid_fov: torch.Tensor,\n",
    "    grid_min_coord: torch.Tensor,\n",
    "    jac_of_warp_type: str = \"deformation\",\n",
    "    compile_jacobian: bool = False,\n",
    "):\n",
    "    jac_of_warp_type = jac_of_warp_type.lower().strip()\n",
    "    deformation_grad = \"deform\" in jac_of_warp_type\n",
    "    displacement_grad = \"displac\" in jac_of_warp_type\n",
    "    assert deformation_grad ^ displacement_grad, (\n",
    "        \"Either deformation_grad or displacement_grad must be True.\"\n",
    "    )\n",
    "    is_training = pred_displacement_net.training\n",
    "    # Set network to eval mode to disable batchnorms, but keep gradients enabled.\n",
    "    pred_displacement_net.eval()\n",
    "\n",
    "    # Reshape everything to be of shape B x 3, to make the vmap easier.\n",
    "    orig_x_shape = tuple(x_coords.shape)\n",
    "    x_coords = einops.rearrange(\n",
    "        x_coords,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    grid_fov = einops.rearrange(\n",
    "        grid_fov,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    grid_min_coord = einops.rearrange(\n",
    "        grid_min_coord,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    # Create function for the Jacobian of the *deformation* field using\n",
    "    # reverse-mode auto-diff.\n",
    "    if deformation_grad:\n",
    "        jac_fn = torch.func.jacrev(\n",
    "            lambda x, f, m: pred_displacement_net(x, f, m) + x, argnums=0\n",
    "        )\n",
    "    else:\n",
    "        jac_fn = torch.func.jacrev(\n",
    "            lambda x, f, m: pred_displacement_net(x, f, m), argnums=0\n",
    "        )\n",
    "    # Vectorize the Jacobian function over the batch size.\n",
    "    # Ensure all Tensors have the same batch size.\n",
    "    grid_fov = grid_fov.expand_as(x_coords)\n",
    "    grid_min_coord = grid_min_coord.expand_as(x_coords)\n",
    "    v_jac_fn = torch.vmap(jac_fn, in_dims=(0, 0, 0), out_dims=0, randomness=\"error\")\n",
    "    if compile_jacobian:\n",
    "        v_jac_fn = torch.compile(v_jac_fn)\n",
    "\n",
    "    # Compute the Jacobian.\n",
    "    J = v_jac_fn(x_coords, grid_fov, grid_min_coord)\n",
    "    # Reshape the batch dims to match the input shape.\n",
    "    J = einops.rearrange(\n",
    "        J,\n",
    "        \"(b x y z) n_coord m_coord -> b x y z n_coord m_coord\",\n",
    "        b=orig_x_shape[0],\n",
    "        x=orig_x_shape[1],\n",
    "        y=orig_x_shape[2],\n",
    "        z=orig_x_shape[3],\n",
    "    )\n",
    "\n",
    "    pred_displacement_net.train(is_training)\n",
    "    return J\n",
    "\n",
    "\n",
    "def bending_energy_regularization(\n",
    "    pred_displacement_net: torch.nn.Module,\n",
    "    x_coords: mrinr.typing.ScalarVolume,\n",
    "    grid_fov: torch.Tensor,\n",
    "    grid_min_coord: torch.Tensor,\n",
    "    pe_dir: str,\n",
    "    hessian_of_warp_type: str = \"deformation\",\n",
    "    compile_hessian: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    hess_of_warp_type = hessian_of_warp_type.lower().strip()\n",
    "    deformation_grad = \"deform\" in hess_of_warp_type\n",
    "    displacement_grad = \"displac\" in hess_of_warp_type\n",
    "    assert deformation_grad ^ displacement_grad, (\n",
    "        \"Either deformation_grad or displacement_grad must be True.\"\n",
    "    )\n",
    "    is_training = pred_displacement_net.training\n",
    "    # Set network to eval mode to disable batchnorms, but keep gradients enabled.\n",
    "    pred_displacement_net.eval()\n",
    "\n",
    "    # Reshape everything to be of shape B x 3, to make the vmap easier.\n",
    "    orig_x_shape = tuple(x_coords.shape)\n",
    "    x_coords = einops.rearrange(\n",
    "        x_coords,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    orig_grid_fov = grid_fov\n",
    "    grid_fov = einops.rearrange(\n",
    "        orig_grid_fov,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    grid_min_coord = einops.rearrange(\n",
    "        grid_min_coord,\n",
    "        \"b x y z coord -> (b x y z) coord\",\n",
    "        coord=3,\n",
    "    )\n",
    "    # Create function for the Hessian of the *deformation* field using\n",
    "    # reverse-mode auto-diff.\n",
    "    if deformation_grad:\n",
    "        hessian_fn = torch.func.hessian(\n",
    "            lambda x, f, m: pred_displacement_net(x, f, m) + x, argnums=0\n",
    "        )\n",
    "    else:\n",
    "        hessian_fn = torch.func.hessian(\n",
    "            lambda x, f, m: pred_displacement_net(x, f, m), argnums=0\n",
    "        )\n",
    "\n",
    "    pe_dir = PE_DIR_ALIASES[pe_dir]\n",
    "    # The Hessian should only be non-zero along the PE direction.\n",
    "    if pe_dir in {\"ap\", \"pa\"}:\n",
    "        hessian_fn_pe = lambda x, f, m: hessian_fn(x, f, m)[\n",
    "            ..., 1\n",
    "        ]  # Y coordinate of the output vector.\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported PE direction: {pe_dir}\")\n",
    "\n",
    "    # Vectorize the Hessian function over the batch size.\n",
    "    # Ensure all Tensors have the same batch size.\n",
    "    grid_fov = grid_fov.expand_as(x_coords)\n",
    "    grid_min_coord = grid_min_coord.expand_as(x_coords)\n",
    "    v_hessian_fn_pe = torch.vmap(\n",
    "        hessian_fn_pe, in_dims=(0, 0, 0), out_dims=0, randomness=\"error\"\n",
    "    )\n",
    "    if compile_hessian:\n",
    "        v_hessian_fn_pe = torch.compile(v_hessian_fn_pe)\n",
    "    # Compute the full 3D, batched Hessian.\n",
    "    H_pe = v_hessian_fn_pe(x_coords, grid_fov, grid_min_coord)\n",
    "    # Reshape the dims to match the input shape.\n",
    "    # Shape of Hessian tensor without batch dims:\n",
    "    # out_dims_m x in_dims_n x in_dims_n\n",
    "    # which is just a batch of Hessian matrices such that for every output dimension k,\n",
    "    # there is a Hessian matrix H_k of all input dimension combinations:\n",
    "    # H_k_ij = d^2 f_k / (d x_i d x_j)\n",
    "    H_pe = einops.rearrange(\n",
    "        H_pe,\n",
    "        \"(b x y z) n_coord_1 n_coord_2 -> b x y z n_coord_1 n_coord_2\",\n",
    "        b=orig_x_shape[0],\n",
    "        x=orig_x_shape[1],\n",
    "        y=orig_x_shape[2],\n",
    "        z=orig_x_shape[3],\n",
    "    )\n",
    "\n",
    "    # Normalizing domain volume/size.\n",
    "    # V = orig_grid_fov.reshape(orig_x_shape[0], 3).prod(dim=-1)\n",
    "    # # Compute bending energy.\n",
    "    # # Sum over all spatial locations and coordinate directions, normalizing by batch-wise\n",
    "    # # FOV/volume.\n",
    "    # l_bending = (\n",
    "    #     einops.reduce(\n",
    "    #         H_pe**2,\n",
    "    #         \"b x y z n_coord_1 n_coord_2 -> b\",\n",
    "    #         \"sum\",\n",
    "    #         b=orig_x_shape[0],\n",
    "    #         x=orig_x_shape[1],\n",
    "    #         y=orig_x_shape[2],\n",
    "    #         z=orig_x_shape[3],\n",
    "    #         n_coord_1=3,\n",
    "    #         n_coord_2=3,\n",
    "    #     )\n",
    "    #     / V\n",
    "    # )\n",
    "    #\n",
    "    # Compute bending energy.\n",
    "    # Sum over all spatial locations and coordinate directions, normalizing by batch-wise\n",
    "    # FOV/volume.\n",
    "    l_bending = einops.reduce(\n",
    "        H_pe**2,\n",
    "        \"b x y z n_coord_1 n_coord_2 -> b x y z\",\n",
    "        \"sum\",\n",
    "        b=orig_x_shape[0],\n",
    "        x=orig_x_shape[1],\n",
    "        y=orig_x_shape[2],\n",
    "        z=orig_x_shape[3],\n",
    "        n_coord_1=3,\n",
    "        n_coord_2=3,\n",
    "    ).mean()\n",
    "    #\n",
    "\n",
    "    pred_displacement_net.train(is_training)\n",
    "    return l_bending\n",
    "\n",
    "\n",
    "def jac_displace_fro_regularization(J_displace: torch.Tensor) -> torch.Tensor:\n",
    "    spatial_dims = 3\n",
    "    # Compute the Jacobian determinant for regularization.\n",
    "    # Last 2 dimensions of J should be the coordinate dimensions.\n",
    "    J = J_displace\n",
    "    assert J.shape[-1] == J.shape[-2] == spatial_dims\n",
    "    J = J.view(-1, spatial_dims, spatial_dims)\n",
    "    l = torch.linalg.matrix_norm(J, ord=\"fro\", dim=(-2, -1)) ** 2\n",
    "    l = l.mean()\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c19706",
   "metadata": {},
   "source": [
    "## Data Processing & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final preprocessing of volumes after loading, but before training.\n",
    "def prep_vols(\n",
    "    b0,\n",
    "    b0_mask,\n",
    "    b0_affine,\n",
    "    t1w,\n",
    "    t1w_mask,\n",
    "    t1w_affine,\n",
    "    scale_kwargs: dict,\n",
    "    blur_mask_kwargs: dict,\n",
    ") -> dict:\n",
    "    # Scale the volumes to have similar intensity ranges.\n",
    "    b0 = scale_vol(b0, **scale_kwargs)\n",
    "    t1w = scale_vol(t1w, **scale_kwargs)\n",
    "    # Blur masks to focus training loss on brain tissue instead of skull/background.\n",
    "    b0_spacing = mrinr.coords.spacing(b0_affine)\n",
    "    b0_mask = blur_mask(b0_mask, spacing=b0_spacing, **blur_mask_kwargs)\n",
    "    t1w_spacing = mrinr.coords.spacing(t1w_affine)\n",
    "    t1w_mask = blur_mask(t1w_mask, spacing=t1w_spacing, **blur_mask_kwargs)\n",
    "    vols = dict(\n",
    "        b0=b0,\n",
    "        b0_mask=b0_mask,\n",
    "        t1w=t1w,\n",
    "        t1w_mask=t1w_mask,\n",
    "    )\n",
    "    return vols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c139151f",
   "metadata": {},
   "source": [
    "## Susceptibility Distortion Field Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43acf8f",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33592d85",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# # Papermill parameters, used by the CLI wrapper script.\n",
    "# in_pml: bool = False\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# params_f: Optional[Path] = None\n",
    "# merge_with_default_params: bool = True\n",
    "compile_hessian: bool = True\n",
    "# save_debug_outputs: bool = True\n",
    "# subj_run_mode: Literal[\"single\"] | Literal[\"batch\"] = \"batch\"\n",
    "# dataset_table_f: Optional[Path] = None\n",
    "# ## Single subject run parameters.\n",
    "# # # Column values for a single subject.\n",
    "# # single_subj_table_f: Optional[Path] = None\n",
    "# # Output paths for a single subject.\n",
    "# single_subj_out_fmap: Optional[Path] = None\n",
    "# single_subj_out_corrected_b0: Optional[Path] = None\n",
    "# single_subj_out_model_weights: Optional[Path] = None\n",
    "# # Directory to save debug/validation results, if requested.\n",
    "# single_subj_out_debug_dir: Optional[Path] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a840891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_dirs = {\n",
    "    \"mica_mics\": Path(\"~/mnt/magpie/outputs/mica_mics/derivatives/epinr_fmap_learning\")\n",
    "    .expanduser()\n",
    "    .resolve(),\n",
    "    \"vcu_ms\": Path(\"~/mnt/magpie/outputs/vcu_ms_epinr/derivatives/epinr_fmap_learning\")\n",
    "    .expanduser()\n",
    "    .resolve(),\n",
    "}\n",
    "# Full dataset table.\n",
    "# _dataset_table_f = Path(\"data_tables/merged_dmri_dataset_table.csv\").resolve()\n",
    "# Subset for ablation studies.\n",
    "_dataset_table_f = Path(\n",
    "    \"data_tables/ablation_merged_subset_dataset_table.csv\"\n",
    ").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae887da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment params\n",
    "params = Box(\n",
    "    dict(\n",
    "        experiment_label=\"epinr_dmri_test\",\n",
    "        dataset_dirs=_dataset_dirs,\n",
    "        dataset_table_f=_dataset_table_f,\n",
    "        result_base_dir=Path(\"~/mnt/magpie/outputs/results/epinr/dmri/epinr/\")\n",
    "        .expanduser()\n",
    "        .resolve(),\n",
    "        epochs=60,\n",
    "        n_repeats_per_epoch=50,\n",
    "        effective_batch_size=6,\n",
    "        batch_size=3,\n",
    "        patch_size=(32, 32, 32),\n",
    "        winsorize_quantiles=(0.01, 0.99),\n",
    "        feature_range=(0.0, 1.0),\n",
    "        mask_blur_sigma_mm=2.0,\n",
    "        mask_blur_truncate=5.0,\n",
    "        # INR model params\n",
    "        hidden_features=256,\n",
    "        num_layers=4,\n",
    "        omega=1.0,\n",
    "        omega_0=30.0,\n",
    "        c=6.0,\n",
    "        # Learnable affine transform params.\n",
    "        # Moving volume non-rigid affine components.\n",
    "        non_rigid_affine_layer=False,\n",
    "        non_rigid_affine_nonzero_thresh=None,\n",
    "        # Fixed volume, refined with rigid affine only.\n",
    "        refine_fixed_rigid_affine=False,\n",
    "        # Percentage of training epochs that will optimize the fixed volume alignment.\n",
    "        # After this percentage of epochs, the fixed volume rigid affine will be\n",
    "        # frozen.\n",
    "        refine_fixed_rigid_affine_epoch_percent=0.0,\n",
    "        # Positional encoding params\n",
    "        m_num_freqs=None,\n",
    "        pos_enc_sigma=None,\n",
    "        pos_enc_type=None,\n",
    "        # Training function params\n",
    "        optim_lr=0.0005,\n",
    "        optim_weight_decay=0.01,\n",
    "        optim_betas=(0.9, 0.999),\n",
    "        # Linear LR scheduler end scale factor.\n",
    "        lr_scheduler_end_factor=0.01,\n",
    "        # Percentage of training epochs for constant warmup and constant cooldown\n",
    "        # phases, both before and after the linear decay phase. Each warmup and cooldown\n",
    "        # phase lasts for this percentage, so the linear decay phase lasts for\n",
    "        # 1 - (2 * this percentage).\n",
    "        lr_scheduler_warmup_cooldown_percent=0.1,\n",
    "        # Whether to use Jacobian modulation during training, and whether to use the\n",
    "        # analytic form from the network, or a finite difference approximation.\n",
    "        enable_jac_mod_in_training=True,\n",
    "        use_analytic_jac_mod=True,\n",
    "        mse_sim_weight=0.0,\n",
    "        mi_sim_weight=1.0,\n",
    "        mi_sim_kwargs=dict(\n",
    "            num_bins=32, sigma_ratio=0.5, norm_mi=False, norm_images=True\n",
    "        ),\n",
    "        ncc_sim_weight=0.0,\n",
    "        lncc_sim_weight=0.0,\n",
    "        lncc_sim_kwargs=dict(kernel_size=9, kernel_type=\"rectangular\"),\n",
    "        laplacian_ncc_sim_weight=0.5,\n",
    "        laplacian_mse_sim_weight=0.0,\n",
    "        laplacian_sigma_low=0.5,\n",
    "        laplacian_truncate=2.0,\n",
    "        jac_fro_reg_weight=1.5,\n",
    "        bending_energy_reg_weight=2.0,\n",
    "        resample_kwargs=dict(\n",
    "            mode_or_interpolation=\"linear\",\n",
    "            padding_mode_or_bound=\"zeros\",\n",
    "            interp_lib=\"torch\",\n",
    "        ),\n",
    "        val_mi_sim_kwargs=dict(kernel_type=\"gaussian\", num_bins=32, sigma_ratio=0.5),\n",
    "    ),\n",
    ")\n",
    "device = torch.device(device)\n",
    "params.result_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "grad_accumulate_steps = params.effective_batch_size / params.batch_size\n",
    "assert grad_accumulate_steps.is_integer(), (\n",
    "    f\"Effective batch size {params.effective_batch_size} must be \"\n",
    "    f\"a multiple of batch size {params.batch_size}.\"\n",
    ")\n",
    "grad_accumulate_steps = int(grad_accumulate_steps)\n",
    "n_batches_per_epoch = params.n_repeats_per_epoch * grad_accumulate_steps\n",
    "viz_validation_every: int = max(params.epochs // 10, 1)  # epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8024c",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(\n",
    "    epinr: EPINR,\n",
    "    subj_data: DWISubjectData,\n",
    "    params: Box,\n",
    "    epoch: int,\n",
    "    step: int,\n",
    "    val_score_fns: dict,\n",
    "    b0_spacing: torch.Tensor,\n",
    "    viz_validation_every: int,\n",
    "    pr=print,\n",
    ") -> dict:\n",
    "    # Convenience functions for resampling volumes.\n",
    "    sample_t1w = lambda c: mrinr.grid_resample(\n",
    "        subj_data.t1w.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.t1w_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "    sample_b0 = lambda c: mrinr.grid_resample(\n",
    "        subj_data.b0.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.b0_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "\n",
    "    # Break up the prediction into smaller chunks to avoid OOM errors.\n",
    "    n_chunks = 16\n",
    "    b0_coord_grid_chunks = torch.chunk(\n",
    "        subj_data.b0_scanner_coord_grid, n_chunks, dim=-2\n",
    "    )\n",
    "    pred_displacement_field_mm_chunks = list()\n",
    "    J_chunks = list()\n",
    "    J_deform_chunks = list()\n",
    "    for b0_coord_grid_chunk in b0_coord_grid_chunks:\n",
    "        pred_displacement_field_mm_chunk = epinr(\n",
    "            x=b0_coord_grid_chunk,\n",
    "            grid_fov=subj_data.b0_fov,\n",
    "            grid_min_coord=subj_data.b0_min_coord,\n",
    "        )\n",
    "        pred_displacement_field_mm_chunks.append(pred_displacement_field_mm_chunk)\n",
    "        J_chunk = jacobian_matrix_batched(\n",
    "            pred_displacement_net=epinr,\n",
    "            x_coords=b0_coord_grid_chunk,\n",
    "            grid_fov=subj_data.b0_fov,\n",
    "            grid_min_coord=subj_data.b0_min_coord,\n",
    "            jac_of_warp_type=\"displacement\",\n",
    "        )\n",
    "        J_chunks.append(J_chunk)\n",
    "        J_deform_chunk = jacobian_matrix_batched(\n",
    "            pred_displacement_net=epinr,\n",
    "            x_coords=b0_coord_grid_chunk,\n",
    "            grid_fov=subj_data.b0_fov,\n",
    "            grid_min_coord=subj_data.b0_min_coord,\n",
    "            jac_of_warp_type=\"deformation\",\n",
    "        )\n",
    "        J_deform_chunks.append(J_deform_chunk)\n",
    "    pred_displacement_field_mm = torch.cat(pred_displacement_field_mm_chunks, dim=-2)\n",
    "    J = torch.cat(J_chunks, dim=-3)\n",
    "    det_J_ap = 1 + J[:, None, ..., 1, 1]\n",
    "    J_deform = torch.cat(J_deform_chunks, dim=-3)\n",
    "    # Sample the moving b0 volume with the predicted displacement field.\n",
    "    moving_b0_sample = det_J_ap * sample_b0(\n",
    "        subj_data.b0_scanner_coord_grid + pred_displacement_field_mm\n",
    "    )\n",
    "\n",
    "    ## Compute validation scores.\n",
    "    # Sample the fixed volume without any affine refinement.\n",
    "    t1w_coord_grid = mrinr.coords.affine_coord_grid(\n",
    "        subj_data.t1w_affine,\n",
    "        subj_data.t1w.shape[-3:],\n",
    "    ).to(subj_data.b0_scanner_coord_grid)\n",
    "    # Sample T1w at the coordinates of the moving image for quant. comparison.\n",
    "    fixed_t1w_sample = sample_t1w(subj_data.b0_scanner_coord_grid)\n",
    "    # Also sample at the full T1w resolution for visualization.\n",
    "    viz_fixed_t1w_sample = sample_t1w(t1w_coord_grid)\n",
    "    if epinr.fixed2moving_rigid_affine is not None:\n",
    "        rigid_refine_fixed_t1w_sample = sample_t1w(\n",
    "            epinr.apply_fixed_rigid_affine(t1w_coord_grid)\n",
    "        )\n",
    "    else:\n",
    "        rigid_refine_fixed_t1w_sample = None\n",
    "    # Convert the topup ground truth displacement field to mm units.\n",
    "    topup_suscept_field_mm = (\n",
    "        subj_data.topup_displace_hz\n",
    "        * subj_data.total_readout_time_s\n",
    "        * b0_spacing[0, 1]\n",
    "        * (-1 if subj_data.pe_dir == \"ap\" else 1)\n",
    "    )[:, 0]\n",
    "    val_scores_epoch_i = {\n",
    "        \"fixed_moving_mi\": val_score_fns[\"fixed_moving_mi\"](\n",
    "            moving_b0_sample, fixed_t1w_sample\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"fixed_moving_ncc\": val_score_fns[\"fixed_moving_ncc\"](\n",
    "            moving_b0_sample, fixed_t1w_sample\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"topup_suscept_mse\": val_score_fns[\"topup_suscept_mse\"](\n",
    "            pred_displacement_field_mm[..., 1], topup_suscept_field_mm\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"topup_corrected_b0_mse\": val_score_fns[\"topup_corrected_b0_mse\"](\n",
    "            moving_b0_sample, subj_data.topup_corrected_b0\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"masked_topup_suscept_mse\": val_score_fns[\"masked_topup_suscept_mse\"](\n",
    "            pred_displacement_field_mm[..., 1],\n",
    "            topup_suscept_field_mm,\n",
    "            subj_data.b0_mask,\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"masked_topup_corrected_b0_mse\": val_score_fns[\"masked_topup_corrected_b0_mse\"](\n",
    "            moving_b0_sample, subj_data.topup_corrected_b0, subj_data.b0_mask\n",
    "        )\n",
    "        .cpu()\n",
    "        .item(),\n",
    "        \"det_J_def_neg_frac\": val_score_fns[\"det_J_def_neg_frac\"](J_deform)\n",
    "        .cpu()\n",
    "        .item(),\n",
    "    }\n",
    "    pr(f\"Validation scores at epoch {epoch}:\")\n",
    "    for metric_name, val_score in val_scores_epoch_i.items():\n",
    "        # val_scores[\"epoch\"].append(epoch)\n",
    "        # val_scores[\"step\"].append(step)\n",
    "        # val_scores[\"metric\"].append(metric_name)\n",
    "        # val_scores[\"val\"].append(val_score)\n",
    "        pr(f\"{metric_name}: {val_score: 10.9f}\", end=\" | \")\n",
    "    pr(flush=True)\n",
    "\n",
    "    if epinr.nonrigid_affine_layer is not None:\n",
    "        pr(\n",
    "            \"Nonrigid affine for moving image\\n\",\n",
    "            {\n",
    "                k: v.detach().cpu().numpy()\n",
    "                for k, v in epinr.nonrigid_affine_layer.named_parameters()\n",
    "            },\n",
    "        )\n",
    "    if epinr.fixed_rigid_affine is not None:\n",
    "        pr(\n",
    "            \"Rigid affine for fixed image refinement:\\n\",\n",
    "            {\n",
    "                k: v.detach().cpu().numpy()\n",
    "                for k, v in epinr.fixed_rigid_affine.named_parameters()\n",
    "            },\n",
    "        )\n",
    "\n",
    "    if viz_validation_every and (\n",
    "        epoch % viz_validation_every == 0 or epoch == params.epochs\n",
    "    ):\n",
    "        plt.clf()\n",
    "        plt.figure(dpi=175)\n",
    "        vols = list()\n",
    "        vol_labels = list()\n",
    "        vols.extend([subj_data.b0, moving_b0_sample, viz_fixed_t1w_sample])\n",
    "        vol_labels.extend([\"In Dist b0\", \"Pred b0 Undist.\", \"T1\"])\n",
    "        if rigid_refine_fixed_t1w_sample is not None:\n",
    "            vols.append(rigid_refine_fixed_t1w_sample)\n",
    "            vol_labels.append(\"Refine T1\")\n",
    "        vols.extend(\n",
    "            [\n",
    "                torch.abs(subj_data.b0 - moving_b0_sample),\n",
    "                subj_data.topup_corrected_b0,\n",
    "                torch.abs(subj_data.topup_corrected_b0 - moving_b0_sample),\n",
    "                subj_data.topup_displace_hz\n",
    "                * subj_data.total_readout_time_s\n",
    "                * b0_spacing[0, 1]\n",
    "                * (-1 if subj_data.pe_dir == \"ap\" else 1),\n",
    "                pred_displacement_field_mm[..., 1],\n",
    "                det_J_ap,\n",
    "            ]\n",
    "        )\n",
    "        vol_labels.extend(\n",
    "            [\n",
    "                \"b0 Dist - Undist\",\n",
    "                \"Topup b0\",\n",
    "                \"Topup - Pred\",\n",
    "                \"Topup Disp mm Y\",\n",
    "                \"Pred Disp mm Y\",\n",
    "                \"Det J\",\n",
    "            ]\n",
    "        )\n",
    "        mrinr.viz.plot_1_ch_multi_slice_compare_vols(\n",
    "            *vols,\n",
    "            colorbars=\"rows\",\n",
    "            vol_labels=vol_labels,\n",
    "            axial_slice_idx=(0.35, 0.5),\n",
    "            saggital_slice_idx=0.45,\n",
    "        )\n",
    "        if epoch != params.epochs:\n",
    "            plt.show()\n",
    "\n",
    "    return {\n",
    "        \"val_scores\": val_scores_epoch_i,\n",
    "        \"pred_displacement_field_mm\": pred_displacement_field_mm[0, ..., 1]\n",
    "        .cpu()\n",
    "        .numpy(),\n",
    "        \"pred_undistorted_b0\": moving_b0_sample[0, 0].cpu().numpy(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd42b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "FULL_EXPERIMENT = True\n",
    "\n",
    "#### Training loop.\n",
    "dataset_table = pd.read_csv(params.dataset_table_f, index_col=None, comment=\"#\")\n",
    "if FULL_EXPERIMENT:\n",
    "    dataset_table_rows = list(range(len(dataset_table)))\n",
    "    # Shuffle subject order to get better estimate of generalization performance, earlier.\n",
    "    np.random.shuffle(dataset_table_rows)\n",
    "    # dataset_table_rows = list(range(2, 10, 3)) + [68] + list(range(24, 35, 3))  #!\n",
    "    timestamp_str = mrinr.utils.timestamp_now()\n",
    "    ### New experiment name.\n",
    "    experiment_name = f\"{timestamp_str}_{params.experiment_label}\"\n",
    "    ### Fixed experiment name.\n",
    "    # experiment_name = \"\"\n",
    "    ###\n",
    "    final_result_dir = params.result_base_dir / experiment_name\n",
    "    experiment_result_dir = final_result_dir\n",
    "    ### Fixed result dir.\n",
    "    # tmp_result_dir_name = final_result_dir.parent / \"\"\n",
    "    ### Random tmp result dir.\n",
    "    tmp_result_dir_name = tempfile.mkdtemp(\n",
    "        dir=final_result_dir.parent,\n",
    "        prefix=f\"tmp-{timestamp_str}-\",\n",
    "        suffix=f\"__{final_result_dir.name}\",\n",
    "    )\n",
    "    ###\n",
    "    del timestamp_str\n",
    "    tmp_result_dir = Path(tmp_result_dir_name)\n",
    "    result_dir = tmp_result_dir\n",
    "    print(f\"Experiment results will be saved to {tmp_result_dir}\")\n",
    "    # Save out parameters used for the experiment.\n",
    "    p = copy.deepcopy(params.to_dict())\n",
    "    with open(result_dir / \"experiment_params.yaml\", \"w\") as f:\n",
    "        yaml.dump(params.to_dict(), f)\n",
    "else:\n",
    "    dataset_table_rows = [45]\n",
    "    result_dir = Path(\"tmp\").resolve()\n",
    "    final_result_dir = None\n",
    "    experiment_result_dir = None\n",
    "\n",
    "for dataset_table_row in dataset_table_rows:\n",
    "    subj_table = dataset_table.iloc[dataset_table_row : (dataset_table_row + 1)]\n",
    "    print(f\"Starting subject {subj_table['subj_id'].values.item()}...\")\n",
    "\n",
    "    # Handle random seeding.\n",
    "    if FULL_EXPERIMENT:\n",
    "        random_seed = mrinr.utils.create_subj_rng_seed(\n",
    "            base_rng_seed=1, subj_id=subj_table[\"subj_id\"].values.item()\n",
    "        ) % (2**32 - 1)\n",
    "    else:\n",
    "        random_seed = np.random.randint(0, 2**32 - 1)\n",
    "        # random_seed = 4221131316\n",
    "    torch.random.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    patch_select_seed = np.random.randint(0, 2**32 - 1)\n",
    "\n",
    "    subj_data = load_dwi_subject_data(\n",
    "        dataset_table=subj_table,\n",
    "        dataset_dirs=params.dataset_dirs,\n",
    "        device=device,\n",
    "    )[0]\n",
    "\n",
    "    # Create a subject-specific result directory.\n",
    "    if FULL_EXPERIMENT:\n",
    "        subj_result_dir = (\n",
    "            result_dir\n",
    "            / f\"{subj_data.dataset_name}_{subj_data.subj_id}_dir-{subj_data.pe_dir}\"\n",
    "        )\n",
    "        subj_result_dir.mkdir(parents=True, exist_ok=True)\n",
    "        completed_indicator_f = subj_result_dir / \"epinr_final_model.pt\"\n",
    "        if completed_indicator_f.exists():\n",
    "            print(\n",
    "                f\"Subject {subj_data.subj_id} already completed,\"\n",
    "                \" skipping to next subject...\"\n",
    "            )\n",
    "            continue\n",
    "        log_f = subj_result_dir / \"log.txt\"\n",
    "        if log_f.exists():\n",
    "            log_mtime_delta = time.time() - os.path.getmtime(log_f)\n",
    "            if log_mtime_delta < 30.0:\n",
    "                print(\n",
    "                    f\"Subject {subj_data.subj_id} is currently running,\"\n",
    "                    \" skipping to next subject...\"\n",
    "                )\n",
    "                continue\n",
    "            log_f.unlink(missing_ok=True)\n",
    "        pr = partial(mrinr.utils.tee, file=log_f)\n",
    "        pr(f\"Subject row:\\n{dataset_table_row}\")\n",
    "    else:\n",
    "        subj_result_dir = result_dir\n",
    "        pr = print\n",
    "\n",
    "    pr(f\"Random seed: {random_seed}\")\n",
    "    pr(f\"Loaded subject {subj_data.dataset_name}, {subj_data.subj_id}.\")\n",
    "    # Store predicted displacement fields and undistorted b0 volumes at each validation\n",
    "    # step.\n",
    "    val_pred_displacement_fields_f = (\n",
    "        subj_result_dir / \"val_pred_displacement_fields.nii.gz\"\n",
    "    )\n",
    "    val_undistorted_b0s_f = subj_result_dir / \"val_undistorted_b0s.nii.gz\"\n",
    "    final_val_fig_f = subj_result_dir / \"final_validation_result.png\"\n",
    "    train_scores_f = subj_result_dir / \"train_scores.csv\"\n",
    "    val_scores_f = subj_result_dir / \"val_scores.csv\"\n",
    "    train_loss_plot_f = subj_result_dir / \"train_loss_plot.png\"\n",
    "    val_scores_plot_f = subj_result_dir / \"val_loss_plot.png\"\n",
    "    val_pred_displacement_fields_list = list()\n",
    "    val_pred_undistorted_b0s_list = list()\n",
    "\n",
    "    # Prep volumes for training.\n",
    "    train_vols = prep_vols(\n",
    "        b0=subj_data.b0,\n",
    "        b0_mask=subj_data.b0_mask,\n",
    "        b0_affine=subj_data.b0_affine,\n",
    "        t1w=subj_data.t1w,\n",
    "        t1w_mask=subj_data.t1w_mask,\n",
    "        t1w_affine=subj_data.t1w_affine,\n",
    "        scale_kwargs=dict(\n",
    "            winsorize_quantiles=params.winsorize_quantiles,\n",
    "            feature_range=params.feature_range,\n",
    "        ),\n",
    "        blur_mask_kwargs=dict(\n",
    "            sigma_mm=params.mask_blur_sigma_mm,\n",
    "            truncate=params.mask_blur_truncate,\n",
    "        ),\n",
    "    )\n",
    "    subj_data.b0 = train_vols[\"b0\"]\n",
    "    subj_data.t1w = train_vols[\"t1w\"]\n",
    "    b0_weight_mask = train_vols[\"b0_mask\"]\n",
    "    t1w_weight_mask = train_vols[\"t1w_mask\"]\n",
    "    subj_data.topup_corrected_b0 = scale_vol(\n",
    "        subj_data.topup_corrected_b0,\n",
    "        winsorize_quantiles=params.winsorize_quantiles,\n",
    "        feature_range=params.feature_range,\n",
    "    )\n",
    "\n",
    "    # Append a batch dimension to all Tensors.\n",
    "    data_d = dict()\n",
    "    for k, v in dataclasses.asdict(subj_data).items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            if \"fov\" in k:\n",
    "                v = einops.rearrange(v, \"ndim -> 1 1 1 ndim\")\n",
    "            elif \"min_coord\" in k:\n",
    "                v = einops.rearrange(v, \"ndim -> 1 1 1 ndim\")\n",
    "            data_d[k] = v.unsqueeze(0)\n",
    "        else:\n",
    "            data_d[k] = v\n",
    "    subj_data = DWISubjectData(**data_d)\n",
    "    b0_spacing = mrinr.coords.spacing(subj_data.b0_affine)\n",
    "    b0_weight_mask.unsqueeze_(0)\n",
    "    t1w_weight_mask.unsqueeze_(0)\n",
    "    # 1 / 0\n",
    "\n",
    "    # Convenience functions for resampling volumes.\n",
    "    sample_t1w = lambda c: mrinr.grid_resample(\n",
    "        subj_data.t1w.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.t1w_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "    sample_b0 = lambda c: mrinr.grid_resample(\n",
    "        subj_data.b0.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.b0_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "    sample_t1w_weight_mask = lambda c: mrinr.grid_resample(\n",
    "        t1w_weight_mask.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.t1w_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "    sample_b0_weight_mask = lambda c: mrinr.grid_resample(\n",
    "        b0_weight_mask.expand(c.shape[0], -1, -1, -1, -1),\n",
    "        affine_x_el2coords=subj_data.b0_affine,\n",
    "        sample_coords=c,\n",
    "        **params.resample_kwargs,\n",
    "    )\n",
    "\n",
    "    # Construct a dataset and dataloader to split up the coordinate grids into patches, to\n",
    "    # save memory during training.\n",
    "    # The dataset needs a non-batched volume with channel dimensions (not coordinate\n",
    "    # dimensions) on the cpu. So, move the coordinate grid to the cpu, remove the batch\n",
    "    # dim, and convert the coord dim to a channel dim.\n",
    "    to_be_patched_coord_grid = mrinr.nn.coords_as_channels(\n",
    "        subj_data.b0_scanner_coord_grid.squeeze(0).cpu(), has_batch_dim=False\n",
    "    )\n",
    "    # Minibatch of smaller patches that are randomly drawn from the coordinate grid.\n",
    "    # Combine the b0 and t1w weight masks for sampling.\n",
    "    combined_b0_t1w_weight_mask = torch.maximum(\n",
    "        sample_b0_weight_mask(subj_data.b0_scanner_coord_grid),\n",
    "        sample_t1w_weight_mask(subj_data.b0_scanner_coord_grid),\n",
    "    )\n",
    "    coord_patch_dataset = monai.data.PatchDataset(\n",
    "        # Data is a shallow copy of the same input coordinate grid, one copy for each batch\n",
    "        # in the epoch.\n",
    "        data=[\n",
    "            {\n",
    "                \"coords\": to_be_patched_coord_grid,\n",
    "                \"weight_mask\": combined_b0_t1w_weight_mask.squeeze(0).cpu(),\n",
    "            }\n",
    "        ]\n",
    "        * n_batches_per_epoch,\n",
    "        patch_func=monai.transforms.RandWeightedCropDict(\n",
    "            keys=\"coords\",\n",
    "            w_key=\"weight_mask\",\n",
    "            spatial_size=params.patch_size,\n",
    "            num_samples=params.batch_size,\n",
    "        ).set_random_state(seed=patch_select_seed),\n",
    "        samples_per_image=params.batch_size,\n",
    "    )\n",
    "    ######\n",
    "    coord_patch_dataloader = monai.data.DataLoader(\n",
    "        coord_patch_dataset,\n",
    "        batch_size=params.batch_size,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=3,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # Instantiate the EPINR model.\n",
    "    epinr = EPINR(\n",
    "        hidden_features=params.hidden_features,\n",
    "        num_layers=params.num_layers,\n",
    "        pe_dir=subj_data.pe_dir,\n",
    "        non_rigid_affine=params.non_rigid_affine_layer,\n",
    "        non_rigid_affine_nonzero_thresh=params.non_rigid_affine_nonzero_thresh,\n",
    "        sigma=params.pos_enc_sigma,\n",
    "        m_num_freqs=params.m_num_freqs,\n",
    "        pos_enc=params.pos_enc_type,\n",
    "        refine_fixed_rigid_affine=params.refine_fixed_rigid_affine,\n",
    "        omega=params.omega,\n",
    "        omega_0=params.omega_0,\n",
    "        c=params.c,\n",
    "    )\n",
    "    epinr.to(device=device)\n",
    "    epinr.train()\n",
    "    pr(\"Model summary:\")\n",
    "    pr(epinr)\n",
    "    # Instantiate the optimizer.\n",
    "    optim = torch.optim.AdamW(\n",
    "        [{\"params\": epinr.network_parameters()}]\n",
    "        + (\n",
    "            [{\"params\": epinr.fixed2moving_rigid_affine_parameters()}]\n",
    "            if params.refine_fixed_rigid_affine\n",
    "            else list()\n",
    "        ),\n",
    "        lr=params.optim_lr / grad_accumulate_steps,\n",
    "        betas=params.optim_betas,\n",
    "        weight_decay=params.optim_weight_decay,\n",
    "        fused=True,\n",
    "    )\n",
    "    pr(\"Optimizer:\")\n",
    "    pr(optim)\n",
    "    optim.zero_grad()\n",
    "    warm_cooldown_epochs = math.ceil(\n",
    "        params.epochs * params.lr_scheduler_warmup_cooldown_percent\n",
    "    )\n",
    "    lin_decay_lr_epochs = params.epochs - (2 * warm_cooldown_epochs)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        optim,\n",
    "        [\n",
    "            torch.optim.lr_scheduler.ConstantLR(\n",
    "                optim, factor=1.0, total_iters=warm_cooldown_epochs\n",
    "            ),\n",
    "            torch.optim.lr_scheduler.LinearLR(\n",
    "                optim,\n",
    "                start_factor=1.0,\n",
    "                end_factor=params.lr_scheduler_end_factor,\n",
    "                total_iters=lin_decay_lr_epochs,\n",
    "            ),\n",
    "            torch.optim.lr_scheduler.ConstantLR(\n",
    "                optim,\n",
    "                factor=params.lr_scheduler_end_factor,\n",
    "                total_iters=warm_cooldown_epochs + 1,\n",
    "            ),\n",
    "        ],\n",
    "        milestones=[warm_cooldown_epochs, lin_decay_lr_epochs + warm_cooldown_epochs],\n",
    "    )\n",
    "    pr(\"LR Scheduler milestones:\")\n",
    "    pr(lr_scheduler._milestones)\n",
    "    if params.refine_fixed_rigid_affine:\n",
    "        stop_rigid_aff_epoch = math.ceil(\n",
    "            params.refine_fixed_rigid_affine_epoch_percent * params.epochs\n",
    "        )\n",
    "        pr(f\"Will stop refining fixed rigid affine at epoch {stop_rigid_aff_epoch}.\")\n",
    "    else:\n",
    "        stop_rigid_aff_epoch = math.inf\n",
    "\n",
    "    # Loss functions.\n",
    "    mse_loss = torch.nn.MSELoss(reduction=\"none\").to(device)\n",
    "    mi_loss = WeightedNMIParzenLoss(**params.mi_sim_kwargs, reduction=\"mean\").to(device)\n",
    "    ncc_loss = NCC(use_mask=False).to(device)\n",
    "    lncc_loss = monai.losses.LocalNormalizedCrossCorrelationLoss(\n",
    "        spatial_dims=3, **params.lncc_sim_kwargs, reduction=\"mean\"\n",
    "    ).to(device)\n",
    "    laplacian_fn = DoGLaplacian(\n",
    "        sigma_low=params.laplacian_sigma_low, truncate=params.laplacian_truncate\n",
    "    ).to(device)\n",
    "    loss_fn = mrinr.nn.loss.WeightedSumLoss(\n",
    "        loss_fns={\n",
    "            \"weighted_mse_sim\": lambda pred, target, weight_mask: (\n",
    "                mse_loss(pred, target) * weight_mask\n",
    "            ).mean(),\n",
    "            \"weighted_mi_sim\": mi_loss,\n",
    "            \"weighted_ncc_sim\": ncc_loss,\n",
    "            \"weighted_lncc_sim\": lncc_loss,\n",
    "            \"laplace_ncc_sim\": lambda pred, target: lncc_loss(\n",
    "                laplacian_fn(pred),\n",
    "                laplacian_fn(1 - target),  # 1-T1w to invert contrast\n",
    "                # laplacian_fn(target),  #! do not invert contrast\n",
    "            ),\n",
    "            \"laplace_mse_sim\": lambda pred, target, weight_mask: (\n",
    "                mse_loss(\n",
    "                    laplacian_fn(pred),\n",
    "                    laplacian_fn(1 - target),  # 1-T1w to invert contrast\n",
    "                    # laplacian_fn(target),  #! do not invert contrast\n",
    "                )\n",
    "                * weight_mask\n",
    "            ).mean(),\n",
    "            \"jac_fro_regularization\": jac_displace_fro_regularization,\n",
    "            \"bending_energy_regularization\": lambda model,\n",
    "            c: bending_energy_regularization(\n",
    "                model,\n",
    "                x_coords=c,\n",
    "                grid_fov=subj_data.b0_fov,\n",
    "                grid_min_coord=subj_data.b0_min_coord,\n",
    "                pe_dir=subj_data.pe_dir,\n",
    "                hessian_of_warp_type=\"deformation\",\n",
    "                compile_hessian=compile_hessian,\n",
    "            ),\n",
    "        },\n",
    "        loss_weights=[\n",
    "            params.mse_sim_weight,\n",
    "            params.mi_sim_weight,\n",
    "            params.ncc_sim_weight,\n",
    "            params.lncc_sim_weight,\n",
    "            params.laplacian_ncc_sim_weight,\n",
    "            params.laplacian_mse_sim_weight,\n",
    "            params.jac_fro_reg_weight,\n",
    "            params.bending_energy_reg_weight,\n",
    "        ],\n",
    "    ).to(device)\n",
    "    val_score_fns = {\n",
    "        \"fixed_moving_mi\": monai.losses.GlobalMutualInformationLoss(\n",
    "            **params.val_mi_sim_kwargs, reduction=\"mean\"\n",
    "        ).to(device),\n",
    "        \"fixed_moving_ncc\": monai.losses.LocalNormalizedCrossCorrelationLoss(\n",
    "            spatial_dims=3, **params.lncc_sim_kwargs, reduction=\"mean\"\n",
    "        ).to(device),\n",
    "        \"topup_suscept_mse\": torch.nn.MSELoss(reduction=\"mean\").to(device),\n",
    "        \"topup_corrected_b0_mse\": torch.nn.MSELoss(reduction=\"mean\").to(device),\n",
    "        \"masked_topup_suscept_mse\": mrinr.nn.loss.WeightedMaskLoss(\n",
    "            \"mse\", reduction=\"mean\"\n",
    "        ).to(device),\n",
    "        \"masked_topup_corrected_b0_mse\": mrinr.nn.loss.WeightedMaskLoss(\n",
    "            \"mse\", reduction=\"mean\"\n",
    "        ).to(device),\n",
    "        \"det_J_def_neg_frac\": lambda J_deform: (\n",
    "            (torch.linalg.det(J_deform) < 0.0).sum()\n",
    "        )\n",
    "        / J_deform[..., 0, 0].numel(),\n",
    "    }\n",
    "\n",
    "    ### Training loop\n",
    "    train_loss = {\n",
    "        \"epoch\": list(),\n",
    "        \"step\": list(),\n",
    "        \"loss_term\": list(),\n",
    "        \"val\": list(),\n",
    "        \"weighted\": list(),\n",
    "    }\n",
    "    accumulate_train_loss = collections.defaultdict(list)\n",
    "    val_scores = {\"epoch\": list(), \"step\": list(), \"metric\": list(), \"val\": list()}\n",
    "    step = 1\n",
    "    batch_step = 1\n",
    "    for epoch in range(1, params.epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        epinr.train()\n",
    "        # Iterate over batches of coordinate patches for this epoch.\n",
    "        for i_epoch_batch, batch_dict in enumerate(coord_patch_dataloader):\n",
    "            if ((i_epoch_batch + 1) % grad_accumulate_steps != 0) and (\n",
    "                i_epoch_batch < (n_batches_per_epoch - 1)\n",
    "            ):\n",
    "                is_accumulating = True\n",
    "            else:\n",
    "                is_accumulating = False\n",
    "\n",
    "            coords = mrinr.nn.channels_as_coords(\n",
    "                batch_dict[\"coords\"].to(device), has_batch_dim=True\n",
    "            )\n",
    "\n",
    "            # Forward pass\n",
    "            pred_displacement_field_mm = epinr(\n",
    "                x=coords,\n",
    "                grid_fov=subj_data.b0_fov,\n",
    "                grid_min_coord=subj_data.b0_min_coord,\n",
    "            )\n",
    "            pred_deformation_field_mm = coords + pred_displacement_field_mm\n",
    "\n",
    "            # Sample the fixed t1w image.\n",
    "            fixed_t1w_sample = sample_t1w(epinr.apply_fixed_rigid_affine(coords))\n",
    "\n",
    "            # Sample moving image with Jacobian modulation at the predicted deformed\n",
    "            # coordinates.\n",
    "            J_pred = jacobian_matrix_batched(\n",
    "                pred_displacement_net=epinr,\n",
    "                x_coords=coords,\n",
    "                grid_fov=subj_data.b0_fov,\n",
    "                grid_min_coord=subj_data.b0_min_coord,\n",
    "                jac_of_warp_type=\"displacement\",\n",
    "                compile_jacobian=True,\n",
    "            )\n",
    "            if params.enable_jac_mod_in_training:\n",
    "                if params.use_analytic_jac_mod:\n",
    "                    det_j_continuous_displace = 1 + J_pred[:, None, ..., 1, 1]\n",
    "                    moving_b0_sample = det_j_continuous_displace * sample_b0(\n",
    "                        pred_deformation_field_mm\n",
    "                    )\n",
    "                else:\n",
    "                    det_J_discrete_displace = central_diff_det_j(\n",
    "                        pred_displacement_field_mm,\n",
    "                        spacing=b0_spacing,\n",
    "                        pe_dir=subj_data.pe_dir,\n",
    "                    )\n",
    "                    moving_b0_sample = det_J_discrete_displace * sample_b0(\n",
    "                        pred_deformation_field_mm\n",
    "                    )\n",
    "            else:\n",
    "                moving_b0_sample = sample_b0(pred_deformation_field_mm)\n",
    "            b0_scanner_space_weight_mask = torch.maximum(\n",
    "                sample_b0_weight_mask(coords),\n",
    "                sample_t1w_weight_mask(epinr.apply_fixed_rigid_affine(coords)),\n",
    "            )\n",
    "            # Compute loss.\n",
    "            loss, loss_term_vals = loss_fn(\n",
    "                weighted_mse_sim=(\n",
    "                    moving_b0_sample,\n",
    "                    fixed_t1w_sample,\n",
    "                    b0_scanner_space_weight_mask,\n",
    "                ),\n",
    "                weighted_mi_sim=(\n",
    "                    moving_b0_sample,\n",
    "                    fixed_t1w_sample,\n",
    "                    b0_scanner_space_weight_mask,\n",
    "                ),\n",
    "                weighted_ncc_sim=(moving_b0_sample, fixed_t1w_sample),\n",
    "                weighted_lncc_sim=(moving_b0_sample, fixed_t1w_sample),\n",
    "                laplace_ncc_sim=(moving_b0_sample, fixed_t1w_sample),\n",
    "                laplace_mse_sim=(\n",
    "                    moving_b0_sample,\n",
    "                    fixed_t1w_sample,\n",
    "                    b0_scanner_space_weight_mask,\n",
    "                ),\n",
    "                jac_fro_regularization=J_pred,\n",
    "                bending_energy_regularization=(epinr, coords),\n",
    "                return_loss_terms=True,\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Record unweighted loss values, along with weighted sum.\n",
    "            for loss_term, loss_val in (\n",
    "                loss_term_vals\n",
    "                | {\"weighted_sum\": {\"value\": loss.detach().cpu().item(), \"weight\": 1.0}}\n",
    "            ).items():\n",
    "                accumulate_train_loss[loss_term].append(loss_val)\n",
    "\n",
    "            if not is_accumulating:\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "                # Store averages of each loss term for this step.\n",
    "                for loss_term, acc_loss_vals_weights in accumulate_train_loss.items():\n",
    "                    l_vals = [l[\"value\"] for l in acc_loss_vals_weights]\n",
    "                    l_weight = [l[\"weight\"] for l in acc_loss_vals_weights]\n",
    "                    loss_value = np.mean(l_vals)\n",
    "                    loss_weight = np.median(l_weight)\n",
    "                    for l_val, is_weighted in zip(\n",
    "                        (loss_value, loss_value * loss_weight), (False, True)\n",
    "                    ):\n",
    "                        train_loss[\"epoch\"].append(epoch)\n",
    "                        train_loss[\"step\"].append(step)\n",
    "                        train_loss[\"loss_term\"].append(loss_term)\n",
    "                        train_loss[\"val\"].append(l_val)\n",
    "                        train_loss[\"weighted\"].append(is_weighted)\n",
    "                        if loss_term == \"weighted_sum\" and not is_weighted:\n",
    "                            loss_str = f\"{loss_value: 10.9f}\"\n",
    "                            pr(f\"{loss_str} | \", end=\"\")\n",
    "                accumulate_train_loss.clear()\n",
    "                # Only update step after the model was updated.\n",
    "                step += 1\n",
    "            # Always update batch_step, even if accumulating.\n",
    "            batch_step += 1\n",
    "        pr()\n",
    "        pr(f\" Epoch {epoch} completed.\")\n",
    "        # Epoch completed, update LR scheduler.\n",
    "        lr_scheduler.step()\n",
    "        if epoch == stop_rigid_aff_epoch:\n",
    "            pr(\"Stopping fixed rigid affine refinement.\")\n",
    "        if epoch >= stop_rigid_aff_epoch:\n",
    "            optim.param_groups[1][\"lr\"] = 0.0\n",
    "        pr(\"Learning rate(s):\")\n",
    "        pr([pg[\"lr\"] for pg in optim.param_groups])\n",
    "\n",
    "        # Validation step\n",
    "        epinr.eval()\n",
    "        with torch.no_grad():\n",
    "            val_results = validation_step(\n",
    "                epinr=epinr,\n",
    "                subj_data=subj_data,\n",
    "                params=params,\n",
    "                epoch=epoch,\n",
    "                step=step,\n",
    "                val_score_fns=val_score_fns,\n",
    "                b0_spacing=b0_spacing,\n",
    "                viz_validation_every=viz_validation_every\n",
    "                if not FULL_EXPERIMENT\n",
    "                else params.epochs,\n",
    "                pr=pr,\n",
    "            )\n",
    "            val_pred_displacement_fields_list.append(\n",
    "                val_results[\"pred_displacement_field_mm\"]\n",
    "            )\n",
    "            val_pred_undistorted_b0s_list.append(val_results[\"pred_undistorted_b0\"])\n",
    "            for k, v in val_results[\"val_scores\"].items():\n",
    "                val_scores[\"epoch\"].append(epoch)\n",
    "                val_scores[\"step\"].append(step)\n",
    "                val_scores[\"metric\"].append(k)\n",
    "                val_scores[\"val\"].append(v)\n",
    "        pr(\"\\n\")\n",
    "\n",
    "    final_pred_displacement_field_mm = val_pred_displacement_fields_list[-1]\n",
    "    final_corrected_b0 = val_pred_undistorted_b0s_list[-1]\n",
    "    train_loss = pd.DataFrame.from_dict(train_loss)\n",
    "    val_scores = pd.DataFrame.from_dict(val_scores)\n",
    "    pr(\"Saving training and validation scores...\")\n",
    "    train_loss.to_csv(train_scores_f, index=False)\n",
    "    val_scores.to_csv(val_scores_f, index=False)\n",
    "    # Save validation predicted displacement fields and undistorted b0s.\n",
    "    if not FULL_EXPERIMENT:\n",
    "        final_val_fig_f.unlink(missing_ok=True)\n",
    "        val_pred_displacement_fields_f.unlink(missing_ok=True)\n",
    "        val_undistorted_b0s_f.unlink(missing_ok=True)\n",
    "    val_pred_displacement_fields_arr = np.stack(\n",
    "        val_pred_displacement_fields_list, axis=-1\n",
    "    )\n",
    "    val_undistorted_b0s_arr = np.stack(val_pred_undistorted_b0s_list, axis=-1)\n",
    "    # pr(\"Saving validation predicted displacement fields and undistorted b0s...\")\n",
    "    # nib.save(\n",
    "    #     nib.Nifti1Image(\n",
    "    #         val_pred_displacement_fields_arr,\n",
    "    #         affine=subj_data.b0_affine.cpu().numpy().squeeze(0),\n",
    "    #     ),\n",
    "    #     val_pred_displacement_fields_f,\n",
    "    # )\n",
    "    # nib.save(\n",
    "    #     nib.Nifti1Image(\n",
    "    #         val_undistorted_b0s_arr,\n",
    "    #         affine=subj_data.b0_affine.cpu().numpy().squeeze(0),\n",
    "    #     ),\n",
    "    #     val_undistorted_b0s_f,\n",
    "    # )\n",
    "    plt.savefig(final_val_fig_f)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation scores.\n",
    "    if not isinstance(train_loss, pd.DataFrame):\n",
    "        train_loss = pd.DataFrame.from_dict(train_loss)\n",
    "        val_scores = pd.DataFrame.from_dict(val_scores)\n",
    "\n",
    "    sns.relplot(\n",
    "        train_loss,\n",
    "        x=\"step\",\n",
    "        y=\"val\",\n",
    "        row=\"weighted\",\n",
    "        col=\"loss_term\",\n",
    "        hue=\"loss_term\",\n",
    "        kind=\"line\",\n",
    "        facet_kws={\"sharey\": \"row\", \"sharex\": True},\n",
    "    )\n",
    "    plt.title(\"Training Losses over Steps\")\n",
    "    plt.savefig(train_loss_plot_f)\n",
    "    if not FULL_EXPERIMENT:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()\n",
    "    sns.relplot(\n",
    "        val_scores,\n",
    "        x=\"step\",\n",
    "        y=\"val\",\n",
    "        col=\"metric\",\n",
    "        hue=\"metric\",\n",
    "        kind=\"line\",\n",
    "        facet_kws={\"sharey\": False, \"sharex\": True},\n",
    "    )\n",
    "    plt.savefig(val_scores_plot_f)\n",
    "    if not FULL_EXPERIMENT:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()\n",
    "\n",
    "    if FULL_EXPERIMENT:\n",
    "        # Save out final predicted displacement field.\n",
    "        final_pred_displacement_mm_f = (\n",
    "            subj_result_dir\n",
    "            / f\"epinr_final_pred_displace_field_dir-{subj_data.pe_dir}_mm.nii.gz\"\n",
    "        )\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                final_pred_displacement_field_mm,\n",
    "                affine=subj_data.b0_affine.cpu().numpy().squeeze(0),\n",
    "            ),\n",
    "            final_pred_displacement_mm_f,\n",
    "        )\n",
    "\n",
    "        final_pred_suscept_field_hz = (\n",
    "            (final_pred_displacement_field_mm * (-1 if subj_data.pe_dir == \"ap\" else 1))\n",
    "            / b0_spacing[0, 1].cpu().numpy()\n",
    "        ) / subj_data.total_readout_time_s\n",
    "        final_pred_displacement_hz_f = (\n",
    "            subj_result_dir / \"epinr_final_pred_suscept_field_hz.nii.gz\"\n",
    "        )\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                final_pred_suscept_field_hz,\n",
    "                affine=subj_data.b0_affine.cpu().numpy().squeeze(0),\n",
    "            ),\n",
    "            final_pred_displacement_hz_f,\n",
    "        )\n",
    "\n",
    "        # Save out the final undistorted b0 by applying the predicted displacement field.\n",
    "        raw_subj_data = load_dwi_subject_data(\n",
    "            dataset_table=subj_table,\n",
    "            dataset_dirs=params.dataset_dirs,\n",
    "            device=device,\n",
    "        )[0]\n",
    "        raw_data_d = dict()\n",
    "        for k, v in dataclasses.asdict(raw_subj_data).items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                if \"fov\" in k:\n",
    "                    v = einops.rearrange(v, \"ndim -> 1 1 1 ndim\")\n",
    "                elif \"min_coord\" in k:\n",
    "                    v = einops.rearrange(v, \"ndim -> 1 1 1 ndim\")\n",
    "                raw_data_d[k] = v.unsqueeze(0)\n",
    "            else:\n",
    "                raw_data_d[k] = v\n",
    "        raw_subj_data = DWISubjectData(**raw_data_d)\n",
    "        epinr.eval()\n",
    "        with torch.no_grad():\n",
    "            raw_corrected_results = validation_step(\n",
    "                epinr=epinr,\n",
    "                subj_data=raw_subj_data,\n",
    "                params=params,\n",
    "                epoch=params.epochs,\n",
    "                step=step,\n",
    "                val_score_fns=val_score_fns,\n",
    "                b0_spacing=b0_spacing,\n",
    "                viz_validation_every=params.epochs + 2,\n",
    "                pr=pr,\n",
    "            )\n",
    "        final_corrected_b0 = raw_corrected_results[\"pred_undistorted_b0\"]\n",
    "        final_corrected_b0_f = subj_result_dir / \"epinr_final_undistorted_b0.nii.gz\"\n",
    "        nib.save(\n",
    "            nib.Nifti1Image(\n",
    "                final_corrected_b0,\n",
    "                affine=raw_subj_data.b0_affine.cpu().numpy().squeeze(0),\n",
    "            ),\n",
    "            final_corrected_b0_f,\n",
    "        )\n",
    "\n",
    "        torch.save(epinr.state_dict(), subj_result_dir / \"epinr_final_model.pt\")\n",
    "        pr(f\"Finished subject {subj_data.dataset_name}, {subj_data.subj_id}.\")\n",
    "\n",
    "if FULL_EXPERIMENT:\n",
    "    # Move the tmp result dir to the final result dir.\n",
    "    print(\n",
    "        f\"Moving temporary result dir\\n{tmp_result_dir}\\nto final directory\\n{final_result_dir}\"\n",
    "    )\n",
    "    tmp_result_dir.rename(final_result_dir)\n",
    "print(\"Done\")\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073f77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a893dfb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac685bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise RuntimeError(\"Stop here, sandbox only beyond this point.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrinr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
